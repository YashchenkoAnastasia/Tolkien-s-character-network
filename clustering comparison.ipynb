{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "import spacy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark import SparkContext\n",
    "from afinn import Afinn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(input_list):\n",
    "    '''\n",
    "    A function to flatten complex list.\n",
    "    :param input_list: The list to be flatten\n",
    "    :return: the flattened list.\n",
    "    '''\n",
    "\n",
    "    flat_list = []\n",
    "    for i in input_list:\n",
    "        if type(i) == list:\n",
    "            flat_list += flatten(i)\n",
    "        else:\n",
    "            flat_list += [i]\n",
    "\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def name_entity_recognition(sentence,names_list):\n",
    "    '''\n",
    "    A function to retrieve name entities in a sentence.\n",
    "    :param sentence: the sentence to retrieve names from.\n",
    "    :return: a name entity list of the sentence.\n",
    "    '''\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    # retrieve person and organization's name from the sentence\n",
    "    name_entity = [x for x in doc.ents if x.label_ in ['PERSON', 'ORG']]\n",
    "    # convert all names to lowercase and remove 's in names\n",
    "    name_entity = [str(x).lower().replace(\"'s\",\"\") for x in name_entity]\n",
    "    # split names into single words ('Harry Potter' -> ['Harry', 'Potter'])\n",
    "    name_entity = [x.split(' ') for x in name_entity]\n",
    "    # flatten the name list\n",
    "    name_entity = flatten(name_entity)\n",
    "    # remove name words that are less than 3 letters to raise recognition accuracy\n",
    "    name_entity = [x for x in name_entity if len(x) >= 3]\n",
    "    # remove name words that are in the set of 4000 common words\n",
    "    name_entity = [x for x in name_entity if x not in common_words]\n",
    "    # remove name words that are in the set of races\n",
    "    name_entity = [x for x in name_entity if x not in races]\n",
    "    #print(name_entity)\n",
    "    for name in name_entity:\n",
    "        names_list.append(name)\n",
    "    return name_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_file = open(r'C:\\Users\\NYashch\\nyashch-projects\\all_sentences.txt','r',encoding = 'utf-8')\n",
    "all_sentences = [line.strip() for line in sent_file]\n",
    "sent_file.close()\n",
    "tolkien_text = ''.join(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntolkien_text_new = []\\nfor sent in tolkien_text.split('.'):\\n    list_sent = sent.split()\\n    if 'Mithrandir' in list_sent:\\n        new_sent = sent.replace('Mithrandir', 'gendalf')\\n        tolkien_text_new.append(new_sent)\\n    elif 'Strider' in list_sent:\\n        new_sent = sent.replace('Strider', 'aragorn')\\n        tolkien_text_new.append(new_sent)\\n    elif 'Gamgee' in list_sent:\\n        new_sent = sent.replace('Gamgee', 'sam')\\n        tolkien_text_new.append(new_sent)\\n    elif 'Meriadoc' in list_sent:\\n        new_sent = sent.replace('Meriadoc', 'merry')\\n        tolkien_text_new.append(new_sent)\\n    elif 'Peregrin' in list_sent:\\n        new_sent = sent.replace('Peregrin', 'pippin')\\n        tolkien_text_new.append(new_sent)\\n    else:\\n        tolkien_text_new.append(new_sent)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tolkien_text_new = []\n",
    "for sent in tolkien_text.split('.'):\n",
    "    list_sent = sent.split()\n",
    "    if 'Mithrandir' in list_sent:\n",
    "        new_sent = sent.replace('Mithrandir', 'gendalf')\n",
    "        tolkien_text_new.append(new_sent)\n",
    "    elif 'Strider' in list_sent:\n",
    "        new_sent = sent.replace('Strider', 'aragorn')\n",
    "        tolkien_text_new.append(new_sent)\n",
    "    elif 'Gamgee' in list_sent:\n",
    "        new_sent = sent.replace('Gamgee', 'sam')\n",
    "        tolkien_text_new.append(new_sent)\n",
    "    elif 'Meriadoc' in list_sent:\n",
    "        new_sent = sent.replace('Meriadoc', 'merry')\n",
    "        tolkien_text_new.append(new_sent)\n",
    "    elif 'Peregrin' in list_sent:\n",
    "        new_sent = sent.replace('Peregrin', 'pippin')\n",
    "        tolkien_text_new.append(new_sent)\n",
    "    else:\n",
    "        tolkien_text_new.append(new_sent)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 24-25: truncated \\UXXXXXXXX escape (<ipython-input-7-bf55be2255d0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-bf55be2255d0>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    '''names = []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 24-25: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "'''names = []\n",
    "f = open(r'C:\\Users\\NYashch\\nyashch-projects\\my_names.txt','r',encoding = 'utf-8')\n",
    "for elem in f.readlines():\n",
    "    elem = elem.replace(\"\\n\",\"\")\n",
    "    names.append(elem)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "my_hobbits = open(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\my_hobbits.txt','r',encoding = 'utf-8')\n",
    "hobbits = []\n",
    "for elem in my_hobbits.readlines():\n",
    "    if len(elem) > 4:\n",
    "        elem = elem.replace(\"\\n\",\"\")\n",
    "        elem = elem.replace(\"\\r\",\"\")\n",
    "        hobbits.append(elem.lower().split()[0])\n",
    "\n",
    "d_hobbits = dict.fromkeys(hobbits, 'hobbit')\n",
    "\n",
    "my_dwarves = open(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\my_dwarves.txt','r',encoding = 'utf-8')\n",
    "dwarves = []\n",
    "\n",
    "for elem in my_dwarves.readlines():\n",
    "    if len(elem) > 4:\n",
    "        elem = elem.replace(\"\\n\",\"\")\n",
    "        elem = elem.replace(\"\\r\",\"\")\n",
    "        dwarves.append(elem.lower().split()[0])\n",
    "d_dwarves = dict.fromkeys(dwarves, 'dwarf')\n",
    "my_elves = open(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\my_elves.txt','r',encoding = 'utf-8')\n",
    "elves = []\n",
    "for elem in my_elves .readlines():\n",
    "    if len(elem) > 4:\n",
    "        elem = elem.replace(\"\\n\",\"\")\n",
    "        elem = elem.replace(\"\\r\",\"\")\n",
    "        elves.append(elem.lower().split()[0])\n",
    "d_elves = dict.fromkeys(elves, 'elf')\n",
    "my_maiar = open(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\my_maiar.txt','r',encoding = 'utf-8')\n",
    "maiar = []\n",
    "for elem in my_maiar.readlines():\n",
    "    if len(elem) > 4:\n",
    "        elem = elem.replace(\"\\n\",\"\")\n",
    "        elem = elem.replace(\"\\r\",\"\")\n",
    "        maiar.append(elem.lower().split()[0])\n",
    "d_maiar = dict.fromkeys(maiar, 'maiar')\n",
    "my_orcs = open(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\my_orcs.txt','r',encoding = 'utf-8')\n",
    "orcs = []\n",
    "for elem in my_orcs.readlines():\n",
    "    if len(elem) > 4:\n",
    "        elem = elem.replace(\"\\n\",\"\")\n",
    "        elem = elem.replace(\"\\r\",\"\")\n",
    "        orcs.append(elem.lower().split()[0])\n",
    "d_orcs = dict.fromkeys(orcs, 'orc')\n",
    "my_men = open(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\my_men.txt','r',encoding = 'utf-8')\n",
    "men = []\n",
    "for elem in my_men.readlines():\n",
    "    if len(elem) > 4:\n",
    "        elem = elem.replace(\"\\n\",\"\")\n",
    "        elem = elem.replace(\"\\r\",\"\")\n",
    "        men.append(elem.lower().split()[0])\n",
    "d_men = dict.fromkeys(men, 'men')\n",
    "my_valars = open(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\my_valars.txt','r',encoding = 'utf-8')\n",
    "valars = []\n",
    "for elem in my_valars.readlines():\n",
    "    if len(elem) > 4:\n",
    "        elem = elem.replace(\"\\n\",\"\")\n",
    "        elem = elem.replace(\"\\r\",\"\")\n",
    "        valars.append(elem.lower())\n",
    "d_valars = dict.fromkeys(valars, 'valar')\n",
    "ainur = [\"ainur\",'aluin','danuin','fanuin','morgoth','ranuin']\n",
    "d_ainur = dict.fromkeys(ainur, 'ainur')\n",
    "barlogs = ['gothmog','lungorthin','osombauko']\n",
    "d_barlogs = dict.fromkeys(barlogs, 'barlog')\n",
    "dragons = ['ancalagon','chrysophylax','glaurung','gostir','scatha','smaug','urulókë']\n",
    "d_dragons = dict.fromkeys(dragons, 'dragon')\n",
    "eagles = ['gwaihir','landroval','meneldor','thornhoth','thorondor','windlord']\n",
    "d_eagles = dict.fromkeys(eagles, 'eagle')\n",
    "ents = ['beechbone','entings','entmaidens','entmoot','entwives','fimbrethil','leaflock','onodrim','quickbeam','skinbark','treebeard']\n",
    "d_ents = dict.fromkeys(ents, 'ent')\n",
    "half_elven = ['ardamir eärendil','arwen','dior','eärendil','elladan','elrohir','elrond','elros','elurín','elwing','undómiel']\n",
    "d_half_elven = dict.fromkeys(half_elven, 'half_elf')\n",
    "werewolves = ['carcharoth','draugluin','thû']\n",
    "d_werewolves = dict.fromkeys(werewolves, 'werewolf')\n",
    "trolls = ['bert','olog-hai','tom','william']\n",
    "d_trolls = dict.fromkeys(trolls, 'troll')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = hobbits + dwarves +elves+maiar+orcs+men+valars+ainur+barlogs+dragons+eagles+ents+half_elven+werewolves+trolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(set(all_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = ['big', 'elven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in extra:\n",
    "        if elem in names:\n",
    "            names.remove(elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names.append('sam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_race = {}\n",
    "for name in names:\n",
    "    if name in d_hobbits:\n",
    "        name_race[name] ='hobbit'\n",
    "    elif name in d_elves:\n",
    "        name_race[name] ='elf'\n",
    "    elif name in  d_dwarves:\n",
    "        name_race[name] ='dwarf'\n",
    "    elif name in  d_trolls:\n",
    "        name_race[name] ='troll'\n",
    "    elif name in  d_werewolves:\n",
    "        name_race[name] ='werewolf'\n",
    "    elif name in  d_ents:\n",
    "        name_race[name] ='ent'\n",
    "    elif name in  d_half_elven:\n",
    "        name_race[name] ='elf'\n",
    "    elif name in  d_eagles:\n",
    "        name_race[name] ='eagle'\n",
    "    elif name in  d_dragons:\n",
    "        name_race[name] ='dragon'\n",
    "    elif name in  d_barlogs:\n",
    "        name_race[name] ='barlog'\n",
    "    elif name in  d_ainur:\n",
    "        name_race[name] ='ainur'\n",
    "    elif name in  d_valars:\n",
    "        name_race[name] ='valar'\n",
    "    elif name in  d_orcs:\n",
    "        name_race[name] ='orc'\n",
    "    elif name in  d_men:\n",
    "        name_race[name] ='man'\n",
    "    elif name in  d_maiar:\n",
    "        name_race[name] ='maiar'\n",
    "    elif name == 'manwë':\n",
    "        name_race[name] ='valar'\n",
    "    elif name == 'sam':\n",
    "        name_race[name] ='hobbit'\n",
    "    elif name == 'melkor':\n",
    "        name_race[name] ='maiar'\n",
    "    elif name =='pippin':\n",
    "        name_race[name] ='hobbit'\n",
    "    elif name == 'arda':\n",
    "        name_race[name] ='arda'\n",
    "\n",
    "    else:\n",
    "        names.remove(name)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = []\n",
    "for name in names:\n",
    "    race.append(name_race[name])\n",
    "race = race[:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_data = {\"name\": names, 'race': race}\n",
    "name_race_df = pd.DataFrame.from_dict(nr_data)\n",
    "name_race_df.to_csv('name_race_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(list(set(race))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ner_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-698a2e6a0209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mner_sentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ner_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "'''from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "d = {}\n",
    "counter = 0\n",
    "for sent in ner_sentences:\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    sent_names = []\n",
    "    for name in names:\n",
    "        if name in sent.lower().split():\n",
    "            sent_names.append(name)\n",
    "    #name_entity_recognition(sent,sent_names)\n",
    "    if len(sent_names) > 1:\n",
    "        for name1 in sent_names:\n",
    "            for name2 in sent_names:\n",
    "                if name1 != name2:\n",
    "                    key = \"\"\n",
    "                    if name1 < name2:\n",
    "                        key = name1 + \"#\" + name2\n",
    "                    else:\n",
    "                        key = name2 + \"#\" + name1\n",
    "                    if d.get(key) == None:\n",
    "                        d[key] =afinn.score(sent)\n",
    "                    else:\n",
    "                        d[key] = d[key]+afinn.score(sent)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''items_list= []\n",
    "for i in d.items():\n",
    "    l = []\n",
    "    line = list(i)[0].split('#')\n",
    "    for elem in line:\n",
    "        l.append(elem)\n",
    "    l.append(list(i)[1])\n",
    "    items_list.append(l)\n",
    "sentiment_counter = -1\n",
    "relations = []\n",
    "for i in items_list:\n",
    "    if i[2] < -5:\n",
    "        relations.append('enemy')\n",
    "    if i[2] > 2:\n",
    "        relations.append('friend')\n",
    "    else:\n",
    "        relations.append('neutral')\n",
    "names1 = []\n",
    "names2 = []\n",
    "edge_colors = []\n",
    "\n",
    "for i in items_list:\n",
    "    sentiment_counter += 1\n",
    "    names1.append(i[0])\n",
    "    names2.append(i[1])\n",
    "    edge_colors.append(relations[sentiment_counter])\n",
    "label_colors = []\n",
    "for name in names1:\n",
    "        label_colors.append(color_map[name])\n",
    "data = {'name1': names1,'name2': names2,'label_color': label_colors,'edge_color': edge_colors}\n",
    "\n",
    "relations_data = pd.DataFrame.from_dict(data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_data.to_csv('relations_data_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDGE BETWENESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_df = pd.read_csv(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\eb_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = list(eb_df['members'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "true_clusters = []\n",
    "for name in cluster_names:\n",
    "    if name in names:\n",
    "        true_clusters.append(name_race[name])\n",
    "    elif name == 'feanor':\n",
    "        true_clusters.append('elf')\n",
    "    elif name == 'luthien':\n",
    "        true_clusters.append('elf')\n",
    "    elif name == 'hurin':\n",
    "        true_clusters.append('man')\n",
    "    elif name == 'earendil':\n",
    "        true_clusters.append('elf')\n",
    "    elif name == 'elurin':\n",
    "        true_clusters.append('elf')\n",
    "    elif name == 'theoden':\n",
    "        true_clusters.append('man')\n",
    "    elif name == 'eomer':\n",
    "        true_clusters.append('elf')\n",
    "    elif name == 'eowyn':\n",
    "        true_clusters.append('elf')\n",
    "    elif name == 'undomiel':\n",
    "        true_clusters.append('elf')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GREEDY MODULARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = pd.read_csv(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\mm_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "mm = list(mm_df['members'])\n",
    "print(len(set(mm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEL PROPOGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_df = pd.read_csv(r'C:\\Users\\NYashch\\nyashch-projects\\Diploma\\lp_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "lp = list(lp_df['members'])\n",
    "print(len(set(lp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003196803752697034"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score(race,mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011915830774922857"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score(race,eb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0035420700277588747"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score(race,lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
